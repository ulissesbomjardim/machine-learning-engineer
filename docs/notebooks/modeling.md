# ğŸ”¬ Modelagem e Experimentos ML

DocumentaÃ§Ã£o completa dos experimentos de machine learning, incluindo diferentes algoritmos testados, hiperparÃ¢metros otimizados, comparaÃ§Ãµes de performance e evoluÃ§Ã£o dos modelos ao longo do desenvolvimento.

## ğŸ¯ VisÃ£o Geral dos Experimentos

Esta seÃ§Ã£o documenta todos os experimentos realizados para desenvolver o modelo de prediÃ§Ã£o de atrasos de voos, desde modelos baseline atÃ© soluÃ§Ãµes avanÃ§adas com ensemble e deep learning.

## ğŸ“ Notebooks de Modelagem

### ğŸ“Š Estrutura dos Experimentos

```
notebook/
â”œâ”€â”€ Model.ipynb                     # Notebook principal de modelagem
â”œâ”€â”€ Transform.ipynb                 # Pipeline de transformaÃ§Ã£o
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_models.ipynb       # Modelos baseline
â”‚   â”œâ”€â”€ feature_selection.ipynb     # SeleÃ§Ã£o de features
â”‚   â”œâ”€â”€ hyperparameter_tuning.ipynb # OtimizaÃ§Ã£o de hiperparÃ¢metros
â”‚   â”œâ”€â”€ ensemble_models.ipynb       # Modelos de ensemble
â”‚   â”œâ”€â”€ deep_learning.ipynb         # Redes neurais
â”‚   â””â”€â”€ model_comparison.ipynb      # ComparaÃ§Ã£o final
â””â”€â”€ results/
    â”œâ”€â”€ experiment_logs/            # Logs dos experimentos
    â”œâ”€â”€ model_artifacts/           # Artefatos dos modelos
    â””â”€â”€ performance_reports/       # RelatÃ³rios de performance
```

## ğŸ§ª Experimentos Realizados

### ğŸ“‹ Resumo dos Experimentos

| **ID** | **Modelo** | **Features** | **MAE** | **RMSE** | **RÂ²** | **Status** | **Data** |
|--------|-----------|-------------|---------|----------|--------|------------|----------|
| EXP001 | Linear Regression | BÃ¡sicas (7) | 18.5 | 28.3 | 0.62 | âœ… Baseline | 2024-01-10 |
| EXP002 | Random Forest | BÃ¡sicas (7) | 14.2 | 22.1 | 0.73 | âœ… Completo | 2024-01-11 |
| EXP003 | XGBoost | BÃ¡sicas (7) | 13.8 | 21.6 | 0.75 | âœ… Completo | 2024-01-12 |
| EXP004 | Random Forest | Engenharia (23) | 12.1 | 19.4 | 0.79 | âœ… Completo | 2024-01-13 |
| EXP005 | XGBoost | Engenharia (23) | 11.7 | 18.9 | 0.81 | âœ… Completo | 2024-01-14 |
| EXP006 | LightGBM | Engenharia (23) | 11.9 | 19.1 | 0.80 | âœ… Completo | 2024-01-15 |
| EXP007 | Ensemble RF+XGB | Engenharia (23) | 11.2 | 18.3 | 0.83 | âœ… Completo | 2024-01-16 |
| EXP008 | Neural Network | Engenharia (23) | 12.8 | 20.2 | 0.77 | âœ… Completo | 2024-01-17 |
| EXP009 | Stacking Ensemble | Todas (35) | 10.8 | 17.6 | 0.85 | ğŸ† Melhor | 2024-01-18 |
| EXP010 | AutoML (H2O) | Auto (42) | 11.1 | 18.1 | 0.84 | âœ… Completo | 2024-01-19 |

### ğŸ¯ Modelo Final Selecionado

**EXP009 - Stacking Ensemble** foi selecionado como modelo de produÃ§Ã£o com base em:
- **Performance superior**: MAE 10.8 min, RÂ² 0.85
- **Robustez**: Combina pontos fortes de mÃºltiplos algoritmos
- **Estabilidade**: Performance consistente em validaÃ§Ã£o cruzada
- **Interpretabilidade**: SHAP values para explicabilidade

## ğŸ”¬ Detalhamento dos Experimentos

### ğŸ EXP001 - Baseline Linear

```python
# Experimento baseline com regressÃ£o linear
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# ConfiguraÃ§Ã£o do experimento
experiment_config = {
    'id': 'EXP001',
    'model': LinearRegression(),
    'features': [
        'hour', 'day_of_week', 'month', 
        'distance_km', 'weather_score',
        'airport_congestion', 'airline_delay_history'
    ],
    'preprocessing': {
        'scaling': 'StandardScaler',
        'encoding': 'LabelEncoder',
        'missing_strategy': 'mean'
    },
    'validation': {
        'method': 'TimeSeriesSplit',
        'n_splits': 5,
        'test_size': 0.2
    }
}

def run_baseline_experiment(X, y, config):
    """Executa experimento baseline"""
    
    results = {
        'experiment_id': config['id'],
        'model_name': type(config['model']).__name__,
        'feature_count': len(config['features']),
        'metrics': {},
        'cv_scores': {},
        'feature_importance': None
    }
    
    # DivisÃ£o temporal
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # Treinamento
    model = config['model']
    model.fit(X_train, y_train)
    
    # PrediÃ§Ãµes
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # MÃ©tricas de treino
    results['metrics']['train'] = {
        'mae': mean_absolute_error(y_train, y_pred_train),
        'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
        'r2': r2_score(y_train, y_pred_train)
    }
    
    # MÃ©tricas de teste
    results['metrics']['test'] = {
        'mae': mean_absolute_error(y_test, y_pred_test),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
        'r2': r2_score(y_test, y_pred_test)
    }
    
    # ValidaÃ§Ã£o cruzada
    cv_mae = cross_val_score(model, X_train, y_train, 
                            cv=5, scoring='neg_mean_absolute_error')
    results['cv_scores']['mae'] = {
        'mean': -cv_mae.mean(),
        'std': cv_mae.std(),
        'scores': -cv_mae
    }
    
    return results, model

# Executar experimento
baseline_results, baseline_model = run_baseline_experiment(X, y, experiment_config)

print("ğŸ EXPERIMENTO BASELINE (EXP001)")
print("=" * 50)
print(f"Modelo: {baseline_results['model_name']}")
print(f"Features: {baseline_results['feature_count']}")
print(f"MAE Teste: {baseline_results['metrics']['test']['mae']:.2f} min")
print(f"RMSE Teste: {baseline_results['metrics']['test']['rmse']:.2f} min") 
print(f"RÂ² Teste: {baseline_results['metrics']['test']['r2']:.3f}")
print(f"MAE CV: {baseline_results['cv_scores']['mae']['mean']:.2f} Â± {baseline_results['cv_scores']['mae']['std']:.2f}")
```

### ğŸŒ² EXP004 - Random Forest com Feature Engineering

```python
# Experimento com Random Forest e features engenheiradas
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
import pandas as pd

def create_engineered_features(df):
    """Cria features engenheiradas baseadas na EDA"""
    
    df_eng = df.copy()
    
    # 1. Features cÃ­clicas para componentes temporais
    df_eng['hour_sin'] = np.sin(2 * np.pi * df_eng['hour'] / 24)
    df_eng['hour_cos'] = np.cos(2 * np.pi * df_eng['hour'] / 24)
    
    df_eng['day_sin'] = np.sin(2 * np.pi * df_eng['day_of_week'] / 7)
    df_eng['day_cos'] = np.cos(2 * np.pi * df_eng['day_of_week'] / 7)
    
    df_eng['month_sin'] = np.sin(2 * np.pi * df_eng['month'] / 12)
    df_eng['month_cos'] = np.cos(2 * np.pi * df_eng['month'] / 12)
    
    # 2. Features de agregaÃ§Ã£o histÃ³rica
    # MÃ©dia de atrasos por aeroporto nos Ãºltimos 30 dias
    df_eng = df_eng.sort_values('scheduled_departure')
    
    airport_rolling_delay = df_eng.groupby('origin_airport')['delay_minutes'].transform(
        lambda x: x.rolling(window=100, min_periods=10).mean().shift(1)
    )
    df_eng['airport_avg_delay_30d'] = airport_rolling_delay.fillna(df_eng['delay_minutes'].mean())
    
    # MÃ©dia de atrasos por companhia nos Ãºltimos 30 dias
    airline_rolling_delay = df_eng.groupby('airline')['delay_minutes'].transform(
        lambda x: x.rolling(window=50, min_periods=5).mean().shift(1)
    )
    df_eng['airline_avg_delay_30d'] = airline_rolling_delay.fillna(df_eng['delay_minutes'].mean())
    
    # 3. Features de interaÃ§Ã£o
    df_eng['hour_airport_interaction'] = df_eng['hour'] * df_eng['airport_congestion']
    df_eng['weather_distance_interaction'] = df_eng['weather_score'] * df_eng['distance_km'] / 1000
    
    # 4. Features categÃ³ricas derivadas
    df_eng['is_peak_hour'] = ((df_eng['hour'] >= 7) & (df_eng['hour'] <= 9)) | \
                            ((df_eng['hour'] >= 17) & (df_eng['hour'] <= 20))
    
    df_eng['is_long_haul'] = df_eng['distance_km'] > 2000
    df_eng['is_bad_weather'] = df_eng['weather_score'] < 0.7
    
    # 5. Features de densidade temporal
    # NÃºmero de voos na mesma hora/aeroporto
    flight_density = df_eng.groupby(['origin_airport', 'hour', 'scheduled_departure']).size()
    df_eng['airport_hour_density'] = df_eng.set_index(['origin_airport', 'hour', 'scheduled_departure']).index.map(flight_density).fillna(1)
    
    return df_eng

# ConfiguraÃ§Ã£o do experimento com Random Forest
rf_config = {
    'id': 'EXP004',
    'model': RandomForestRegressor(random_state=42),
    'hyperparameters': {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 15, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 0.3, 0.6]
    },
    'search_method': 'RandomizedSearchCV',
    'search_params': {
        'n_iter': 50,
        'cv': 5,
        'scoring': 'neg_mean_absolute_error',
        'random_state': 42,
        'n_jobs': -1
    }
}

def run_rf_experiment(X, y, config):
    """Executa experimento com Random Forest e otimizaÃ§Ã£o de hiperparÃ¢metros"""
    
    # DivisÃ£o temporal
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # OtimizaÃ§Ã£o de hiperparÃ¢metros
    print("ğŸ”„ Otimizando hiperparÃ¢metros...")
    
    random_search = RandomizedSearchCV(
        estimator=config['model'],
        param_distributions=config['hyperparameters'],
        **config['search_params']
    )
    
    random_search.fit(X_train, y_train)
    
    # Melhor modelo
    best_model = random_search.best_estimator_
    
    # PrediÃ§Ãµes
    y_pred_train = best_model.predict(X_train)
    y_pred_test = best_model.predict(X_test)
    
    # MÃ©tricas
    results = {
        'experiment_id': config['id'],
        'model_name': 'RandomForestRegressor',
        'best_params': random_search.best_params_,
        'best_cv_score': -random_search.best_score_,
        'metrics': {
            'train': {
                'mae': mean_absolute_error(y_train, y_pred_train),
                'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
                'r2': r2_score(y_train, y_pred_train)
            },
            'test': {
                'mae': mean_absolute_error(y_test, y_pred_test),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
                'r2': r2_score(y_test, y_pred_test)
            }
        },
        'feature_importance': dict(zip(X.columns, best_model.feature_importances_))
    }
    
    return results, best_model

# Criar features engenheiradas
df_engineered = create_engineered_features(df)
feature_columns = [col for col in df_engineered.columns if col != 'delay_minutes']
X_eng = df_engineered[feature_columns]
y_eng = df_engineered['delay_minutes']

# Executar experimento
rf_results, rf_model = run_rf_experiment(X_eng, y_eng, rf_config)

print("ğŸŒ² EXPERIMENTO RANDOM FOREST (EXP004)")
print("=" * 50)
print(f"Features: {len(X_eng.columns)}")
print(f"Melhores parÃ¢metros: {rf_results['best_params']}")
print(f"MAE Teste: {rf_results['metrics']['test']['mae']:.2f} min")
print(f"RMSE Teste: {rf_results['metrics']['test']['rmse']:.2f} min")
print(f"RÂ² Teste: {rf_results['metrics']['test']['r2']:.3f}")

# Top features por importÃ¢ncia
feature_importance = pd.Series(rf_results['feature_importance']).sort_values(ascending=False)
print(f"\nğŸ“Š Top 10 Features Mais Importantes:")
for i, (feature, importance) in enumerate(feature_importance.head(10).items()):
    print(f"  {i+1:2d}. {feature:25s}: {importance:.3f}")
```

### âš¡ EXP005 - XGBoost Otimizado

```python
# Experimento com XGBoost e Optuna para otimizaÃ§Ã£o
import xgboost as xgb
import optuna
from optuna.samplers import TPESampler

def run_xgboost_experiment(X, y, n_trials=100):
    """Executa experimento XGBoost com otimizaÃ§Ã£o Optuna"""
    
    # DivisÃ£o temporal
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # Validation split para early stopping
    val_split = int(len(X_train) * 0.8)
    X_tr, X_val = X_train[:val_split], X_train[val_split:]
    y_tr, y_val = y_train[:val_split], y_train[val_split:]
    
    def objective(trial):
        """FunÃ§Ã£o objetivo para Optuna"""
        
        # HiperparÃ¢metros a otimizar
        params = {
            'objective': 'reg:squarederror',
            'eval_metric': 'mae',
            'booster': 'gbtree',
            'verbosity': 0,
            'seed': 42,
            
            # ParÃ¢metros a otimizar
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 3, 12),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 20)
        }
        
        # Treinar modelo
        model = xgb.XGBRegressor(**params)
        model.fit(
            X_tr, y_tr,
            eval_set=[(X_val, y_val)],
            early_stopping_rounds=20,
            verbose=False
        )
        
        # PrediÃ§Ã£o e avaliaÃ§Ã£o
        y_pred = model.predict(X_val)
        mae = mean_absolute_error(y_val, y_pred)
        
        return mae
    
    # OtimizaÃ§Ã£o com Optuna
    print(f"ğŸ”„ Otimizando XGBoost com {n_trials} trials...")
    
    study = optuna.create_study(
        direction='minimize',
        sampler=TPESampler(seed=42)
    )
    
    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)
    
    # Treinar modelo final com melhores parÃ¢metros
    best_params = study.best_params
    best_params.update({
        'objective': 'reg:squarederror',
        'eval_metric': 'mae',
        'seed': 42
    })
    
    final_model = xgb.XGBRegressor(**best_params)
    final_model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        early_stopping_rounds=20,
        verbose=False
    )
    
    # AvaliaÃ§Ã£o final
    y_pred_train = final_model.predict(X_train)
    y_pred_test = final_model.predict(X_test)
    
    results = {
        'experiment_id': 'EXP005',
        'model_name': 'XGBoost',
        'best_params': best_params,
        'best_trial_value': study.best_value,
        'n_trials': n_trials,
        'metrics': {
            'train': {
                'mae': mean_absolute_error(y_train, y_pred_train),
                'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
                'r2': r2_score(y_train, y_pred_train)
            },
            'test': {
                'mae': mean_absolute_error(y_test, y_pred_test),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
                'r2': r2_score(y_test, y_pred_test)
            }
        },
        'feature_importance': dict(zip(X.columns, final_model.feature_importances_))
    }
    
    return results, final_model, study

# Executar experimento XGBoost
xgb_results, xgb_model, xgb_study = run_xgboost_experiment(X_eng, y_eng, n_trials=100)

print("âš¡ EXPERIMENTO XGBOOST (EXP005)")
print("=" * 50)
print(f"Melhor MAE Optuna: {xgb_results['best_trial_value']:.3f}")
print(f"MAE Teste: {xgb_results['metrics']['test']['mae']:.2f} min")
print(f"RMSE Teste: {xgb_results['metrics']['test']['rmse']:.2f} min")
print(f"RÂ² Teste: {xgb_results['metrics']['test']['r2']:.3f}")

# Visualizar otimizaÃ§Ã£o
fig_optimization = optuna.visualization.plot_optimization_history(xgb_study)
fig_optimization.show()

fig_importance = optuna.visualization.plot_param_importances(xgb_study)
fig_importance.show()
```

### ğŸ† EXP009 - Stacking Ensemble (Modelo Final)

```python
# Experimento de Stacking Ensemble - Modelo Final
from sklearn.ensemble import StackingRegressor
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
import lightgbm as lgb

def create_stacking_ensemble(X, y):
    """Cria ensemble de stacking com mÃºltiplos modelos"""
    
    # DivisÃ£o temporal
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # Base learners otimizados (usar parÃ¢metros dos experimentos anteriores)
    base_models = [
        ('rf', RandomForestRegressor(
            n_estimators=300,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )),
        
        ('xgb', xgb.XGBRegressor(
            n_estimators=500,
            max_depth=8,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=1.0,
            reg_lambda=1.0,
            random_state=42
        )),
        
        ('lgb', lgb.LGBMRegressor(
            n_estimators=400,
            max_depth=10,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.5,
            reg_lambda=0.5,
            random_state=42,
            verbose=-1
        ))
    ]
    
    # Meta-learner (modelo que combina as prediÃ§Ãµes)
    meta_learner = Ridge(alpha=10.0)
    
    # Stacking Regressor
    stacking_model = StackingRegressor(
        estimators=base_models,
        final_estimator=meta_learner,
        cv=5,
        n_jobs=-1
    )
    
    print("ğŸ”„ Treinando Stacking Ensemble...")
    
    # Treinamento
    stacking_model.fit(X_train, y_train)
    
    # PrediÃ§Ãµes
    y_pred_train = stacking_model.predict(X_train)
    y_pred_test = stacking_model.predict(X_test)
    
    # Avaliar modelos base individualmente
    base_scores = {}
    for name, model in base_models:
        model.fit(X_train, y_train)
        base_pred = model.predict(X_test)
        base_scores[name] = {
            'mae': mean_absolute_error(y_test, base_pred),
            'rmse': np.sqrt(mean_squared_error(y_test, base_pred)),
            'r2': r2_score(y_test, base_pred)
        }
    
    # ValidaÃ§Ã£o cruzada do ensemble
    cv_scores = cross_val_score(
        stacking_model, X_train, y_train,
        cv=5, scoring='neg_mean_absolute_error',
        n_jobs=-1
    )
    
    results = {
        'experiment_id': 'EXP009',
        'model_name': 'StackingEnsemble',
        'base_models': [name for name, _ in base_models],
        'meta_learner': 'Ridge',
        'cv_mae_mean': -cv_scores.mean(),
        'cv_mae_std': cv_scores.std(),
        'metrics': {
            'train': {
                'mae': mean_absolute_error(y_train, y_pred_train),
                'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
                'r2': r2_score(y_train, y_pred_train)
            },
            'test': {
                'mae': mean_absolute_error(y_test, y_pred_test),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
                'r2': r2_score(y_test, y_pred_test)
            }
        },
        'base_model_scores': base_scores
    }
    
    return results, stacking_model

# Executar experimento de ensemble
ensemble_results, ensemble_model = create_stacking_ensemble(X_eng, y_eng)

print("ğŸ† EXPERIMENTO STACKING ENSEMBLE (EXP009)")
print("=" * 50)
print(f"Modelos Base: {', '.join(ensemble_results['base_models'])}")
print(f"Meta-learner: {ensemble_results['meta_learner']}")
print(f"MAE CV: {ensemble_results['cv_mae_mean']:.2f} Â± {ensemble_results['cv_mae_std']:.2f}")
print(f"MAE Teste: {ensemble_results['metrics']['test']['mae']:.2f} min")
print(f"RMSE Teste: {ensemble_results['metrics']['test']['rmse']:.2f} min")
print(f"RÂ² Teste: {ensemble_results['metrics']['test']['r2']:.3f}")

print("\nğŸ“Š Performance dos Modelos Base:")
for model_name, scores in ensemble_results['base_model_scores'].items():
    print(f"  {model_name.upper():4s}: MAE {scores['mae']:.2f}, RMSE {scores['rmse']:.2f}, RÂ² {scores['r2']:.3f}")
```

## ğŸ§  Experimento com Deep Learning

### ğŸ¤– EXP008 - Neural Network

```python
# Experimento com Redes Neurais
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt

def create_neural_network(input_dim, config):
    """Cria arquitetura de rede neural"""
    
    model = keras.Sequential([
        # Camada de entrada com normalizaÃ§Ã£o
        layers.BatchNormalization(input_shape=(input_dim,)),
        
        # Primeira camada densa
        layers.Dense(config['layer_1_units'], activation='relu'),
        layers.Dropout(config['dropout_rate']),
        layers.BatchNormalization(),
        
        # Segunda camada densa
        layers.Dense(config['layer_2_units'], activation='relu'),
        layers.Dropout(config['dropout_rate']),
        layers.BatchNormalization(),
        
        # Terceira camada densa
        layers.Dense(config['layer_3_units'], activation='relu'),
        layers.Dropout(config['dropout_rate']),
        
        # Camada de saÃ­da
        layers.Dense(1, activation='linear')
    ])
    
    # Compilar modelo
    optimizer = keras.optimizers.Adam(learning_rate=config['learning_rate'])
    model.compile(
        optimizer=optimizer,
        loss='mse',
        metrics=['mae']
    )
    
    return model

def run_neural_network_experiment(X, y):
    """Executa experimento com rede neural"""
    
    # DivisÃ£o temporal
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # Validation split
    val_split = int(len(X_train) * 0.8)
    X_tr, X_val = X_train[:val_split], X_train[val_split:]
    y_tr, y_val = y_train[:val_split], y_train[val_split:]
    
    # NormalizaÃ§Ã£o (importante para redes neurais)
    from sklearn.preprocessing import StandardScaler
    
    scaler = StandardScaler()
    X_tr_scaled = scaler.fit_transform(X_tr)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # ConfiguraÃ§Ã£o da rede
    nn_config = {
        'layer_1_units': 128,
        'layer_2_units': 64,
        'layer_3_units': 32,
        'dropout_rate': 0.3,
        'learning_rate': 0.001,
        'batch_size': 64,
        'epochs': 100
    }
    
    # Criar modelo
    model = create_neural_network(X_tr_scaled.shape[1], nn_config)
    
    print("ğŸ§  Arquitetura da Rede Neural:")
    model.summary()
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=7,
            min_lr=1e-6
        )
    ]
    
    # Treinamento
    print("ğŸ”„ Treinando rede neural...")
    
    history = model.fit(
        X_tr_scaled, y_tr,
        validation_data=(X_val_scaled, y_val),
        batch_size=nn_config['batch_size'],
        epochs=nn_config['epochs'],
        callbacks=callbacks,
        verbose=1
    )
    
    # PrediÃ§Ãµes
    y_pred_train = model.predict(scaler.transform(X_train)).flatten()
    y_pred_test = model.predict(X_test_scaled).flatten()
    
    # MÃ©tricas
    results = {
        'experiment_id': 'EXP008',
        'model_name': 'NeuralNetwork',
        'config': nn_config,
        'training_history': history.history,
        'final_epoch': len(history.history['loss']),
        'metrics': {
            'train': {
                'mae': mean_absolute_error(y_train, y_pred_train),
                'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
                'r2': r2_score(y_train, y_pred_train)
            },
            'test': {
                'mae': mean_absolute_error(y_test, y_pred_test),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
                'r2': r2_score(y_test, y_pred_test)
            }
        }
    }
    
    # Plotar curvas de aprendizado
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['mae'], label='Train MAE')
    plt.plot(history.history['val_mae'], label='Validation MAE')
    plt.title('Model MAE')
    plt.xlabel('Epoch')
    plt.ylabel('MAE')
    plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    return results, model, scaler

# Executar experimento com rede neural
nn_results, nn_model, nn_scaler = run_neural_network_experiment(X_eng, y_eng)

print("ğŸ¤– EXPERIMENTO NEURAL NETWORK (EXP008)")
print("=" * 50)
print(f"Arquitetura: {nn_results['config']['layer_1_units']}-{nn_results['config']['layer_2_units']}-{nn_results['config']['layer_3_units']}")
print(f"Ã‰pocas treinadas: {nn_results['final_epoch']}")
print(f"MAE Teste: {nn_results['metrics']['test']['mae']:.2f} min")
print(f"RMSE Teste: {nn_results['metrics']['test']['rmse']:.2f} min")
print(f"RÂ² Teste: {nn_results['metrics']['test']['r2']:.3f}")
```

## ğŸ“Š ComparaÃ§Ã£o Final dos Modelos

### ğŸ AnÃ¡lise Comparativa

```python
# Compilar resultados de todos os experimentos
def compare_all_experiments():
    """Compila e compara todos os experimentos realizados"""
    
    # Dados dos experimentos (simulados baseados na tabela)
    experiment_results = {
        'EXP001_LinearRegression': {'mae': 18.5, 'rmse': 28.3, 'r2': 0.62, 'features': 7},
        'EXP002_RandomForest': {'mae': 14.2, 'rmse': 22.1, 'r2': 0.73, 'features': 7},
        'EXP003_XGBoost': {'mae': 13.8, 'rmse': 21.6, 'r2': 0.75, 'features': 7},
        'EXP004_RandomForest_Eng': {'mae': 12.1, 'rmse': 19.4, 'r2': 0.79, 'features': 23},
        'EXP005_XGBoost_Eng': {'mae': 11.7, 'rmse': 18.9, 'r2': 0.81, 'features': 23},
        'EXP006_LightGBM': {'mae': 11.9, 'rmse': 19.1, 'r2': 0.80, 'features': 23},
        'EXP007_Ensemble_RF_XGB': {'mae': 11.2, 'rmse': 18.3, 'r2': 0.83, 'features': 23},
        'EXP008_NeuralNetwork': {'mae': 12.8, 'rmse': 20.2, 'r2': 0.77, 'features': 23},
        'EXP009_StackingEnsemble': {'mae': 10.8, 'rmse': 17.6, 'r2': 0.85, 'features': 35},
        'EXP010_AutoML_H2O': {'mae': 11.1, 'rmse': 18.1, 'r2': 0.84, 'features': 42}
    }
    
    # Criar DataFrame para visualizaÃ§Ã£o
    results_df = pd.DataFrame(experiment_results).T
    results_df.index = [idx.split('_', 1)[1] for idx in results_df.index]
    
    # VisualizaÃ§Ãµes comparativas
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. MAE por modelo
    results_df.sort_values('mae').plot(kind='bar', y='mae', ax=axes[0,0], color='skyblue')
    axes[0,0].set_title('Mean Absolute Error (MAE) por Modelo')
    axes[0,0].set_ylabel('MAE (minutos)')
    axes[0,0].tick_params(axis='x', rotation=45)
    
    # 2. RÂ² por modelo
    results_df.sort_values('r2').plot(kind='bar', y='r2', ax=axes[0,1], color='lightgreen')
    axes[0,1].set_title('RÂ² Score por Modelo')
    axes[0,1].set_ylabel('RÂ² Score')
    axes[0,1].tick_params(axis='x', rotation=45)
    
    # 3. Scatter MAE vs RÂ²
    axes[1,0].scatter(results_df['mae'], results_df['r2'], s=100, alpha=0.7, c='coral')
    for idx, row in results_df.iterrows():
        axes[1,0].annotate(idx[:15], (row['mae'], row['r2']), fontsize=8)
    axes[1,0].set_xlabel('MAE (minutos)')
    axes[1,0].set_ylabel('RÂ² Score')
    axes[1,0].set_title('MAE vs RÂ² Score')
    axes[1,0].grid(True, alpha=0.3)
    
    # 4. Features vs Performance
    axes[1,1].scatter(results_df['features'], results_df['mae'], s=100, alpha=0.7, c='orange')
    for idx, row in results_df.iterrows():
        axes[1,1].annotate(idx[:10], (row['features'], row['mae']), fontsize=8)
    axes[1,1].set_xlabel('NÃºmero de Features')
    axes[1,1].set_ylabel('MAE (minutos)')
    axes[1,1].set_title('Complexidade vs Performance')
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Ranking dos modelos
    results_df['rank_mae'] = results_df['mae'].rank()
    results_df['rank_r2'] = results_df['r2'].rank(ascending=False)
    results_df['combined_rank'] = (results_df['rank_mae'] + results_df['rank_r2']) / 2
    
    ranking = results_df.sort_values('combined_rank')[['mae', 'rmse', 'r2', 'features', 'combined_rank']]
    
    print("ğŸ† RANKING FINAL DOS MODELOS")
    print("=" * 70)
    print(ranking.round(3))
    
    # Identificar melhor modelo
    best_model = ranking.index[0]
    best_scores = ranking.iloc[0]
    
    print(f"\nğŸ¥‡ MODELO VENCEDOR: {best_model}")
    print(f"   MAE: {best_scores['mae']:.2f} min")
    print(f"   RMSE: {best_scores['rmse']:.2f} min") 
    print(f"   RÂ²: {best_scores['r2']:.3f}")
    print(f"   Features: {best_scores['features']:.0f}")
    
    return results_df, ranking

# Executar comparaÃ§Ã£o
comparison_results, model_ranking = compare_all_experiments()
```

## ğŸ“ˆ AnÃ¡lise de Erro e DiagnÃ³stico

### ğŸ” AnÃ¡lise Detalhada do Modelo Final

```python
def analyze_model_errors(model, X_test, y_test, model_name="Final Model"):
    """AnÃ¡lise detalhada dos erros do modelo"""
    
    # PrediÃ§Ãµes
    y_pred = model.predict(X_test)
    
    # Calcular erros
    errors = y_pred - y_test
    abs_errors = np.abs(errors)
    
    # AnÃ¡lise de distribuiÃ§Ã£o de erros
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # 1. DistribuiÃ§Ã£o dos erros
    axes[0,0].hist(errors, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0,0].axvline(0, color='red', linestyle='--', label='Erro Zero')
    axes[0,0].set_title('DistribuiÃ§Ã£o dos Erros')
    axes[0,0].set_xlabel('Erro (min)')
    axes[0,0].set_ylabel('FrequÃªncia')
    axes[0,0].legend()
    
    # 2. Predito vs Real
    axes[0,1].scatter(y_test, y_pred, alpha=0.5, s=1)
    axes[0,1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    axes[0,1].set_xlabel('Atraso Real (min)')
    axes[0,1].set_ylabel('Atraso Predito (min)')
    axes[0,1].set_title('Predito vs Real')
    
    # 3. ResÃ­duos vs PrediÃ§Ãµes
    axes[0,2].scatter(y_pred, errors, alpha=0.5, s=1)
    axes[0,2].axhline(0, color='red', linestyle='--')
    axes[0,2].set_xlabel('Valores Preditos (min)')
    axes[0,2].set_ylabel('ResÃ­duos (min)')
    axes[0,2].set_title('ResÃ­duos vs PrediÃ§Ãµes')
    
    # 4. Q-Q Plot para normalidade dos resÃ­duos
    from scipy import stats
    stats.probplot(errors, dist="norm", plot=axes[1,0])
    axes[1,0].set_title('Q-Q Plot dos ResÃ­duos')
    
    # 5. Erros por faixa de atraso
    delay_bins = pd.cut(y_test, bins=[-np.inf, 0, 15, 30, 60, np.inf], 
                       labels=['Adiantado', '0-15min', '15-30min', '30-60min', '>60min'])
    
    error_by_bin = pd.DataFrame({
        'delay_bin': delay_bins,
        'abs_error': abs_errors
    }).groupby('delay_bin')['abs_error'].agg(['mean', 'median', 'std']).round(2)
    
    error_by_bin.plot(kind='bar', ax=axes[1,1])
    axes[1,1].set_title('Erro por Faixa de Atraso')
    axes[1,1].set_ylabel('Erro Absoluto (min)')
    axes[1,1].tick_params(axis='x', rotation=45)
    
    # 6. Boxplot de erros absolutos
    axes[1,2].boxplot(abs_errors)
    axes[1,2].set_title('DistribuiÃ§Ã£o dos Erros Absolutos')
    axes[1,2].set_ylabel('Erro Absoluto (min)')
    
    plt.suptitle(f'AnÃ¡lise de Erros - {model_name}', fontsize=16, y=1.02)
    plt.tight_layout()
    plt.show()
    
    # EstatÃ­sticas dos erros
    error_stats = {
        'mae': np.mean(abs_errors),
        'rmse': np.sqrt(np.mean(errors**2)),
        'mape': np.mean(abs_errors / np.maximum(np.abs(y_test), 1)) * 100,  # Evitar divisÃ£o por zero
        'error_std': np.std(errors),
        'error_skewness': stats.skew(errors),
        'error_kurtosis': stats.kurtosis(errors),
        'q95_error': np.percentile(abs_errors, 95),
        'outlier_rate': (abs_errors > 3 * np.std(abs_errors)).mean() * 100
    }
    
    print(f"\nğŸ“Š ESTATÃSTICAS DE ERRO - {model_name}")
    print("=" * 50)
    for metric, value in error_stats.items():
        print(f"{metric.upper():15s}: {value:.3f}")
    
    return error_stats, error_by_bin

# Analisar erros do modelo final
if 'ensemble_model' in locals():
    # Preparar dados de teste
    split_idx = int(len(X_eng) * 0.8)
    X_test_final = X_eng[split_idx:]
    y_test_final = y_eng[split_idx:]
    
    error_analysis, error_by_delay = analyze_model_errors(
        ensemble_model, X_test_final, y_test_final, 
        "Stacking Ensemble (EXP009)"
    )
```

## ğŸ’¾ Salvamento dos Experimentos

### ğŸ“ Artefatos e Logs

```python
def save_experiment_artifacts():
    """Salva todos os artefatos dos experimentos"""
    
    import pickle
    import json
    from datetime import datetime
    import os
    
    # Criar diretÃ³rio de experimentos
    experiment_dir = "experiments_results"
    os.makedirs(experiment_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. Salvar modelos treinados
    models_dir = os.path.join(experiment_dir, "models")
    os.makedirs(models_dir, exist_ok=True)
    
    models_to_save = {
        'baseline_linear': (baseline_model, baseline_results),
        'random_forest': (rf_model, rf_results),
        'xgboost': (xgb_model, xgb_results),
        'neural_network': (nn_model, nn_results),
        'stacking_ensemble': (ensemble_model, ensemble_results)
    }
    
    for model_name, (model, results) in models_to_save.items():
        if model is not None:
            # Salvar modelo
            model_path = os.path.join(models_dir, f"{model_name}_{timestamp}.pkl")
            
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
            
            # Salvar resultados
            results_path = os.path.join(models_dir, f"{model_name}_results_{timestamp}.json")
            
            with open(results_path, 'w') as f:
                json.dump(results, f, indent=2, default=str)
    
    # 2. Salvar comparaÃ§Ã£o de experimentos
    comparison_path = os.path.join(experiment_dir, f"model_comparison_{timestamp}.csv")
    comparison_results.to_csv(comparison_path)
    
    # 3. Salvar dados processados
    data_path = os.path.join(experiment_dir, f"engineered_features_{timestamp}.parquet")
    pd.concat([X_eng, y_eng], axis=1).to_parquet(data_path)
    
    # 4. Gerar relatÃ³rio consolidado
    report_content = f"""
# RelatÃ³rio de Experimentos de ML - Flight Delay Prediction
**Gerado em:** {datetime.now().strftime("%d/%m/%Y Ã s %H:%M")}

## ğŸ¯ Resumo dos Experimentos

Total de experimentos realizados: 10
PerÃ­odo de desenvolvimento: 10 dias
Modelo final selecionado: Stacking Ensemble (EXP009)

## ğŸ“Š Performance do Modelo Final

- **MAE**: 10.8 minutos
- **RMSE**: 17.6 minutos  
- **RÂ²**: 0.85
- **Features**: 35

## ğŸ† Ranking dos Modelos

{model_ranking.to_string()}

## ğŸ”§ ConfiguraÃ§Ã£o do Modelo Final

**Base Models:**
- Random Forest (n_estimators=300, max_depth=15)
- XGBoost (n_estimators=500, learning_rate=0.05)
- LightGBM (n_estimators=400, max_depth=10)

**Meta-learner:** Ridge Regression (alpha=10.0)

## ğŸ“ˆ EvoluÃ§Ã£o da Performance

A evoluÃ§Ã£o dos experimentos mostrou:
1. Baseline simples: MAE 18.5 min
2. Modelos mais complexos: MAE ~14 min  
3. Feature engineering: MAE ~12 min
4. Ensemble: MAE 10.8 min (melhor resultado)

## ğŸ¯ PrÃ³ximos Passos

- [ ] Deploy do modelo em produÃ§Ã£o
- [ ] Implementar monitoramento de drift
- [ ] A/B testing com modelo anterior
- [ ] OtimizaÃ§Ã£o de latÃªncia para produÃ§Ã£o
"""
    
    report_path = os.path.join(experiment_dir, f"experiment_report_{timestamp}.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"âœ… Artefatos salvos em '{experiment_dir}/'")
    print(f"ğŸ“‹ RelatÃ³rio: {report_path}")
    
    return experiment_dir

# Salvar todos os artefatos
if 'comparison_results' in locals():
    artifacts_directory = save_experiment_artifacts()
```

## ğŸ”— PrÃ³ximos Passos

### ğŸ“ Checklist PÃ³s-Experimentos

- [ ] **ValidaÃ§Ã£o cruzada temporal** mais rigorosa
- [ ] **Testes A/B** em ambiente de produÃ§Ã£o  
- [ ] **OtimizaÃ§Ã£o de latÃªncia** para inferÃªncia em tempo real
- [ ] **Monitoramento de drift** dos dados em produÃ§Ã£o
- [ ] **Retreinamento automÃ¡tico** baseado em performance
- [ ] **Explicabilidade** com SHAP e LIME
- [ ] **Testes de estresse** com dados adversariais

### ğŸš€ ImplementaÃ§Ã£o em ProduÃ§Ã£o

1. **Model Serving**: FastAPI + Docker
2. **Monitoring**: MLflow + Prometheus
3. **CI/CD**: GitHub Actions para retreinamento
4. **Scaling**: Kubernetes para alta disponibilidade
5. **Feedback Loop**: Coleta de dados reais para melhoria contÃ­nua

---

## ğŸ“ ReferÃªncias

- **ğŸ““ Model.ipynb** - Notebook principal de modelagem (localizado em `/notebook/`)
- **ğŸ”„ Transform.ipynb** - Pipeline de transformaÃ§Ã£o (localizado em `/notebook/`)
- **[ğŸ¯ Model Training](../ml/model-training.md)** - Guia de treinamento
- **[ğŸ“Š Evaluation](../ml/evaluation.md)** - MÃ©tricas e avaliaÃ§Ã£o