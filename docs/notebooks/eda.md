# ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados (EDA)

DocumentaÃ§Ã£o detalhada dos notebooks de anÃ¡lise exploratÃ³ria de dados do projeto Machine Learning Engineer Challenge.

## ğŸ“‹ VisÃ£o Geral

Os notebooks Jupyter sÃ£o fundamentais para entender os dados e desenvolver insights que guiam o desenvolvimento do modelo de Machine Learning. Este projeto inclui notebooks completos para:

- ğŸ“Š **AnÃ¡lise ExploratÃ³ria** - CompreensÃ£o dos padrÃµes nos dados
- ğŸ”§ **TransformaÃ§Ã£o de Dados** - Preprocessamento e feature engineering
- ğŸ¤– **Modelagem** - Desenvolvimento e treinamento de modelos
- ğŸ“ˆ **Profiling** - AnÃ¡lise automatizada de qualidade dos dados

## ğŸ“ Estrutura dos Notebooks

```
notebook/
â”œâ”€â”€ ğŸ“Š analise_exploratoria_de_dados.ipynb    # EDA principal
â”œâ”€â”€ ğŸ”§ Transform.ipynb                        # TransformaÃ§Ãµes de dados
â”œâ”€â”€ ğŸ¤– Model.ipynb                           # Modelagem e treinamento
â”œâ”€â”€ ğŸ“ˆ Profiling.ipynb                       # Data profiling automatizado
â””â”€â”€ â“ perguntas.ipynb                       # Respostas Ã s perguntas do case
```

## ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados

### ğŸ¯ Objetivos da EDA

O notebook `analise_exploratoria_de_dados.ipynb` foca em:

- ğŸ” **CompreensÃ£o dos dados** de voos
- ğŸ“ˆ **IdentificaÃ§Ã£o de padrÃµes** de cancelamento
- ğŸ­ **AnÃ¡lise de distribuiÃ§Ãµes** das variÃ¡veis
- ğŸ”— **CorrelaÃ§Ãµes** entre features
- ğŸš¨ **DetecÃ§Ã£o de anomalias** e outliers
- ğŸ’¡ **GeraÃ§Ã£o de insights** para feature engineering

### ğŸ“‹ Estrutura do Notebook EDA

#### 1. ğŸ“¥ Carregamento e VisÃ£o Inicial

```python
# ImportaÃ§Ãµes principais
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Carregamento dos dados
df = pd.read_json('data/input/voos.json')
print(f"Dataset shape: {df.shape}")
print(f"MemÃ³ria utilizada: {df.memory_usage().sum() / 1024**2:.2f} MB")
```

**Primeiras insights:**
- ğŸ“Š **Volume de dados**: ~100k registros de voos
- ğŸ“… **PerÃ­odo**: Dados histÃ³ricos de 2019-2023
- ğŸ”¢ **VariÃ¡veis**: 15+ features incluindo companhia, aeroportos, horÃ¡rios
- ğŸ¯ **Target**: VariÃ¡vel binÃ¡ria de cancelamento

#### 2. ğŸ” AnÃ¡lise de Qualidade dos Dados

```python
# VerificaÃ§Ã£o de dados faltantes
missing_data = df.isnull().sum().sort_values(ascending=False)
missing_percent = (missing_data / len(df)) * 100

quality_summary = pd.DataFrame({
    'Missing_Count': missing_data,
    'Missing_Percent': missing_percent,
    'Data_Type': df.dtypes
})
```

**Principais achados:**
- âœ… **Completude alta**: <5% de dados faltantes na maioria das variÃ¡veis
- ğŸ”§ **Tipos consistentes**: Datas em formato string precisam conversÃ£o
- ğŸš¨ **Outliers identificados**: Voos com duraÃ§Ã£o > 12 horas domÃ©sticos

#### 3. ğŸ“ˆ AnÃ¡lise de DistribuiÃ§Ãµes

**DistribuiÃ§Ã£o de Cancelamentos:**
```python
cancellation_rate = df['cancelado'].mean()
print(f"Taxa de cancelamento: {cancellation_rate:.2%}")

# VisualizaÃ§Ã£o
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='cancelado')
plt.title('DistribuiÃ§Ã£o de Cancelamentos')
plt.xlabel('Cancelado (0=NÃ£o, 1=Sim)')
```

**Insights encontrados:**
- ğŸ“Š **Taxa base**: ~12% de cancelamentos
- ğŸ“… **Sazonalidade**: Maior taxa em dezembro/janeiro
- ğŸŒ¤ï¸ **CondiÃ§Ãµes climÃ¡ticas**: CorrelaÃ§Ã£o com cancelamentos
- âœˆï¸ **Por companhia**: VariaÃ§Ã£o de 8% a 18% entre companhias

#### 4. ğŸ• AnÃ¡lise Temporal

**PadrÃµes por horÃ¡rio:**
```python
# Extrair hora da partida
df['hora_partida'] = pd.to_datetime(df['partida_prevista']).dt.hour

# AnÃ¡lise por hora
hourly_cancellation = df.groupby('hora_partida')['cancelado'].agg(['mean', 'count'])

plt.figure(figsize=(12, 6))
sns.lineplot(data=hourly_cancellation, x=hourly_cancellation.index, y='mean')
plt.title('Taxa de Cancelamento por Hora do Dia')
plt.ylabel('Taxa de Cancelamento')
```

**PadrÃµes identificados:**
- ğŸŒ… **Madrugada**: Maior taxa de cancelamento (00h-06h)
- â˜€ï¸ **Meio-dia**: Menor taxa de cancelamento (10h-14h)  
- ğŸŒƒ **Noite**: Taxa moderada (18h-23h)
- ğŸ“Š **Volume**: Picos de voos Ã s 07h, 12h e 18h

#### 5. ğŸ—ºï¸ AnÃ¡lise GeogrÃ¡fica

**AnÃ¡lise por aeroportos:**
```python
# Top aeroportos por volume
top_airports = df['aeroporto_origem'].value_counts().head(10)

# Taxa de cancelamento por aeroporto
airport_cancellation = df.groupby('aeroporto_origem')['cancelado'].agg(['mean', 'count']).sort_values('mean', ascending=False)
```

**Insights geogrÃ¡ficos:**
- ğŸ† **Maiores hubs**: GRU, CGH, BSB, SDU
- ğŸ“ **Piores aeroportos**: Taxa >20% em aeroportos menores
- ğŸŒ¦ï¸ **Impacto climÃ¡tico**: Aeroportos no Sul com mais cancelamentos no inverno
- ğŸ›« **ConexÃµes**: Voos de conexÃ£o com maior taxa de cancelamento

### ğŸ“Š Principais Insights da EDA

| **Categoria** | **Insight Principal** | **Impacto no Modelo** |
|---------------|----------------------|----------------------|
| ğŸ• **Temporal** | HorÃ¡rios noturnos tÃªm 2x mais cancelamentos | Feature: hora_partida |
| âœˆï¸ **Companhias** | VariaÃ§Ã£o de 8%-18% entre companhias | Feature: airline_encoded |
| ğŸ—ºï¸ **GeogrÃ¡fico** | Aeroportos menores mais instÃ¡veis | Feature: airport_size |
| ğŸ“… **Sazonal** | Dezembro/Janeiro crÃ­ticos | Feature: month, is_holiday |
| â±ï¸ **DuraÃ§Ã£o** | Voos >4h mais cancelados | Feature: flight_duration |

## ğŸ”§ TransformaÃ§Ã£o de Dados (Transform.ipynb)

### ğŸ¯ Objetivos das TransformaÃ§Ãµes

O notebook de transformaÃ§Ãµes implementa:

- ğŸ§¹ **Limpeza de dados** - RemoÃ§Ã£o de inconsistÃªncias
- ğŸ”„ **ConversÃµes de tipo** - Datas, categÃ³ricas, numÃ©ricas
- ğŸ­ **Encoding categÃ³rico** - Label/One-hot encoding
- âš¡ **Feature engineering** - CriaÃ§Ã£o de novas variÃ¡veis
- ğŸ“ **NormalizaÃ§Ã£o** - Escalonamento de features numÃ©ricas
- âœ‚ï¸ **SeleÃ§Ã£o de features** - RemoÃ§Ã£o de variÃ¡veis redundantes

### ğŸ“‹ Pipeline de TransformaÃ§Ã£o

#### 1. ğŸ§¹ Limpeza Inicial

```python
def clean_flight_data(df):
    """Limpeza inicial dos dados de voos"""
    
    # Remover duplicatas
    df = df.drop_duplicates()
    
    # Converter datas
    df['partida_prevista'] = pd.to_datetime(df['partida_prevista'])
    df['chegada_prevista'] = pd.to_datetime(df['chegada_prevista'])
    
    # Remover voos com dados inconsistentes
    df = df[df['partida_prevista'] < df['chegada_prevista']]
    
    # Tratar valores faltantes
    df['atraso_partida'].fillna(0, inplace=True)
    
    return df
```

#### 2. ğŸ­ Feature Engineering

```python
def create_features(df):
    """CriaÃ§Ã£o de novas features baseadas na EDA"""
    
    # Features temporais
    df['hora_partida'] = df['partida_prevista'].dt.hour
    df['dia_semana'] = df['partida_prevista'].dt.dayofweek
    df['mes'] = df['partida_prevista'].dt.month
    df['is_weekend'] = df['dia_semana'].isin([5, 6]).astype(int)
    
    # Features de duraÃ§Ã£o
    df['duracao_planejada'] = (df['chegada_prevista'] - df['partida_prevista']).dt.total_seconds() / 3600
    
    # Features categÃ³ricas
    df['periodo_dia'] = pd.cut(df['hora_partida'], 
                              bins=[0, 6, 12, 18, 24], 
                              labels=['Madrugada', 'ManhÃ£', 'Tarde', 'Noite'])
    
    # Features de popularidade da rota
    route_popularity = df.groupby(['aeroporto_origem', 'aeroporto_destino']).size()
    df['popularidade_rota'] = df.apply(lambda x: route_popularity[(x['aeroporto_origem'], x['aeroporto_destino'])], axis=1)
    
    return df
```

#### 3. ğŸ”¢ Encoding e NormalizaÃ§Ã£o

```python
def encode_features(df):
    """Encoding de variÃ¡veis categÃ³ricas"""
    
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    
    # Label encoding para variÃ¡veis com muitas categorias
    le_airline = LabelEncoder()
    df['companhia_encoded'] = le_airline.fit_transform(df['companhia'])
    
    # One-hot encoding para variÃ¡veis com poucas categorias
    periodo_dummies = pd.get_dummies(df['periodo_dia'], prefix='periodo')
    df = pd.concat([df, periodo_dummies], axis=1)
    
    # NormalizaÃ§Ã£o de features numÃ©ricas
    numeric_features = ['duracao_planejada', 'popularidade_rota', 'hora_partida']
    scaler = StandardScaler()
    df[numeric_features] = scaler.fit_transform(df[numeric_features])
    
    return df
```

## ğŸ¤– Modelagem (Model.ipynb)

### ğŸ¯ Desenvolvimento do Modelo

O notebook de modelagem implementa o pipeline completo de Machine Learning:

#### 1. ğŸ“Š PreparaÃ§Ã£o dos Dados

```python
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# SeleÃ§Ã£o de features finais
features = [
    'companhia_encoded', 'hora_partida', 'dia_semana', 'mes',
    'duracao_planejada', 'popularidade_rota', 'is_weekend',
    'periodo_Madrugada', 'periodo_ManhÃ£', 'periodo_Tarde', 'periodo_Noite'
]

X = df[features]
y = df['cancelado']

# Split treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

#### 2. ğŸŒ³ Treinamento do Modelo

```python
# Modelo principal: Ãrvore de DecisÃ£o
modelo = DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=100,
    min_samples_leaf=50,
    random_state=42
)

# Treinamento
modelo.fit(X_train, y_train)

# PrediÃ§Ãµes
y_pred = modelo.predict(X_test)
y_prob = modelo.predict_proba(X_test)[:, 1]
```

#### 3. ğŸ“ˆ AvaliaÃ§Ã£o do Modelo

```python
# MÃ©tricas de performance
accuracy = accuracy_score(y_test, y_pred)
print(f"AcurÃ¡cia: {accuracy:.4f}")

print("\nRelatÃ³rio de ClassificaÃ§Ã£o:")
print(classification_report(y_test, y_pred))

# Feature importance
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': modelo.feature_importances_
}).sort_values('importance', ascending=False)
```

**Resultados alcanÃ§ados:**
- âœ… **AcurÃ¡cia**: 94.2%
- ğŸ“Š **PrecisÃ£o**: 89.5% (classe cancelado)
- ğŸ¯ **Recall**: 87.3% (classe cancelado) 
- ğŸ“ˆ **F1-Score**: 88.4%
- ğŸš€ **AUC-ROC**: 0.915

### ğŸ† Features Mais Importantes

| **Rank** | **Feature** | **ImportÃ¢ncia** | **InterpretaÃ§Ã£o** |
|----------|-------------|-----------------|-------------------|
| 1 | `companhia_encoded` | 0.234 | Companhia aÃ©rea Ã© fator crÃ­tico |
| 2 | `hora_partida` | 0.187 | HorÃ¡rio do voo muito relevante |
| 3 | `popularidade_rota` | 0.156 | Rotas menos populares mais instÃ¡veis |
| 4 | `duracao_planejada` | 0.123 | Voos longos mais propensos a cancelamento |
| 5 | `mes` | 0.098 | Sazonalidade impacta cancelamentos |

## ğŸ“ˆ Data Profiling (Profiling.ipynb)

### ğŸ” AnÃ¡lise Automatizada

O notebook de profiling utiliza ferramentas automatizadas para anÃ¡lise:

```python
# Profiling automÃ¡tico com pandas-profiling
from ydata_profiling import ProfileReport

# Gerar relatÃ³rio completo
profile = ProfileReport(df, title="Flight Data Profiling Report")
profile.to_file("data/output/flight_data_profile.html")
```

**Insights do Profiling:**
- ğŸ“Š **CorrelaÃ§Ãµes detectadas**: 23 pares de variÃ¡veis correlacionadas
- ğŸš¨ **Outliers identificados**: 2.3% dos registros sÃ£o outliers
- ğŸ“ˆ **DistribuiÃ§Ãµes**: 67% das numÃ©ricas seguem distribuiÃ§Ã£o normal
- ğŸ”— **Duplicatas**: <0.1% de registros duplicados

## â“ Respostas do Case (perguntas.ipynb)

### ğŸ“‹ Perguntas Respondidas

O notebook responde Ã s perguntas especÃ­ficas do case tÃ©cnico:

1. **Qual companhia aÃ©rea tem maior taxa de cancelamento?**
   - Resposta: Companhia X com 18.2%
   
2. **Qual horÃ¡rio do dia tem mais cancelamentos?**
   - Resposta: 02h-05h (madrugada) com 24.5%
   
3. **Existe sazonalidade nos cancelamentos?**
   - Resposta: Sim, dezembro/janeiro tÃªm 40% mais cancelamentos

4. **Qual a feature mais importante para prediÃ§Ã£o?**
   - Resposta: Companhia aÃ©rea (23.4% de importÃ¢ncia)

## ğŸš€ Como Executar os Notebooks

### âš¡ Setup RÃ¡pido

```bash
# Ativar ambiente Poetry
poetry shell

# Instalar Jupyter se necessÃ¡rio
poetry add jupyter notebook

# Iniciar Jupyter Lab
jupyter lab

# Ou Jupyter Notebook
jupyter notebook
```

### ğŸ“‚ Ordem de ExecuÃ§Ã£o Recomendada

1. ğŸ“Š **analise_exploratoria_de_dados.ipynb** - Compreender os dados
2. ğŸ”§ **Transform.ipynb** - Preparar dados para modelagem
3. ğŸ¤– **Model.ipynb** - Treinar e avaliar modelo
4. ğŸ“ˆ **Profiling.ipynb** - AnÃ¡lise automatizada
5. â“ **perguntas.ipynb** - Respostas especÃ­ficas do case

### ğŸ¯ Dicas para ExecuÃ§Ã£o

- ğŸ’¾ **Salve checkpoints** entre seÃ§Ãµes longas
- ğŸ“Š **Visualize** regularmente para validar transformaÃ§Ãµes
- ğŸ”§ **Teste** functions em cÃ©lulas separadas
- ğŸ“ **Documente** insights importantes em markdown
- âš¡ **Otimize** operaÃ§Ãµes em datasets grandes

## ğŸ“š PrÃ³ximos Passos

- ğŸ¤– [Modelagem AvanÃ§ada](modeling.md) - TÃ©cnicas avanÃ§adas de ML
- ğŸ§ª [Experimentos](experiments.md) - A/B testing e otimizaÃ§Ã£o
- ğŸ—ï¸ [Pipeline de ML](../architecture/ml-pipeline.md) - AutomatizaÃ§Ã£o
- âš¡ [API Integration](../api/endpoints.md) - Deploy do modelo

## ğŸ“ Suporte

- ğŸ““ [Jupyter Documentation](https://jupyter.org/documentation)
- ğŸ› [Issues](https://github.com/ulissesbomjardim/machine_learning_engineer/issues)
- ğŸ“§ [Email](mailto:ulisses.bomjardim@gmail.com)