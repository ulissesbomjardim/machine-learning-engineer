# ğŸ§ª Experimentos e Notebooks

DocumentaÃ§Ã£o completa dos experimentos realizados, notebooks de anÃ¡lise e metodologias utilizadas no desenvolvimento do sistema de prediÃ§Ã£o de atrasos de voos.

## ğŸ““ Notebooks DisponÃ­veis

### ğŸ¯ Notebooks Principais

| **Notebook** | **DescriÃ§Ã£o** | **Status** | **Ãšltima AtualizaÃ§Ã£o** |
|-------------|---------------|------------|------------------------|
| `analise_exploratoria_de_dados.ipynb` | EDA completa dos dados de voos | âœ… Completo | 2024-01-20 |
| `Model.ipynb` | Desenvolvimento e comparaÃ§Ã£o de modelos | âœ… Completo | 2024-01-18 |
| `Transform.ipynb` | Pipeline de transformaÃ§Ã£o de dados | âœ… Completo | 2024-01-15 |
| `Profiling.ipynb` | Profiling detalhado dos dados | âœ… Completo | 2024-01-12 |
| `perguntas.ipynb` | InvestigaÃ§Ã£o de questÃµes especÃ­ficas | âœ… Completo | 2024-01-10 |

### ğŸ§ª Experimentos de Modelagem

#### ğŸ“Š Cronologia dos Experimentos

```mermaid
timeline
    title Cronologia dos Experimentos de ML
    
    Jan 10 : EXP001 - Baseline Linear
           : MAE 18.5 min
           
    Jan 11 : EXP002 - Random Forest BÃ¡sico
           : MAE 14.2 min
           
    Jan 12 : EXP003 - XGBoost BÃ¡sico
           : MAE 13.8 min
           
    Jan 13 : EXP004 - Random Forest + Feature Engineering
           : MAE 12.1 min
           
    Jan 14 : EXP005 - XGBoost Otimizado
           : MAE 11.7 min
           
    Jan 15 : EXP006 - LightGBM
           : MAE 11.9 min
           
    Jan 16 : EXP007 - Ensemble RF+XGB
           : MAE 11.2 min
           
    Jan 17 : EXP008 - Neural Network
           : MAE 12.8 min
           
    Jan 18 : EXP009 - Stacking Ensemble
           : MAE 10.8 min (FINAL)
           
    Jan 19 : EXP010 - AutoML H2O
           : MAE 11.1 min
```

## ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados

### ğŸ¯ Objetivo da EDA

A anÃ¡lise exploratÃ³ria foi conduzida para:

1. **Entender os dados**: DistribuiÃ§Ãµes, padrÃµes e anomalias
2. **Identificar features relevantes**: VariÃ¡veis que impactam atrasos
3. **Descobrir insights**: PadrÃµes temporais, geogrÃ¡ficos e operacionais
4. **Guiar feature engineering**: CriaÃ§Ã£o de novas variÃ¡veis
5. **Definir estratÃ©gias**: Preprocessamento e modelagem

### ğŸ“ˆ Principais Descobertas

```python
# Principais insights da EDA
eda_insights = {
    'temporal_patterns': {
        'peak_delay_hours': [17, 18, 19, 20],  # 17h-20h
        'worst_day': 'Friday',  # Sexta-feira
        'seasonal_impact': 'Winter months show 15% more delays'
    },
    
    'geographic_patterns': {
        'worst_airports': ['ORD', 'ATL', 'LAX'],  # Por volume e clima
        'best_airports': ['SEA', 'PDX', 'SLC'],   # Menor congestionamento
        'route_impact': 'Long-haul flights 23% more delays'
    },
    
    'weather_impact': {
        'strongest_correlation': 'visibility',  # -0.45 com atrasos
        'temperature_effect': 'Extremes (< 0Â°C or > 35Â°C) increase delays',
        'wind_threshold': '25+ mph doubles delay probability'
    },
    
    'operational_factors': {
        'airline_variance': '2.5x difference between best and worst',
        'aircraft_impact': 'Older aircraft models +8min average delay',
        'capacity_effect': 'Full flights +12% delay probability'
    }
}
```

### ğŸŒŸ Insights Principais

#### ğŸ• PadrÃµes Temporais
- **HorÃ¡rios de pico**: 17h-20h apresentam 40% mais atrasos
- **Dias da semana**: Sextas-feiras tÃªm os maiores atrasos (mÃ©dia +8 min)
- **Sazonalidade**: Meses de inverno mostram 15% mais atrasos
- **Feriados**: VÃ©speras de feriados aumentam atrasos em 25%

#### ğŸŒ PadrÃµes GeogrÃ¡ficos
- **Aeroportos problemÃ¡ticos**: ORD, ATL, LAX devido ao volume e clima
- **Rotas crÃ­ticas**: Voos transcontinentais tÃªm 23% mais atrasos
- **RegiÃµes**: Costa leste mais afetada por condiÃ§Ãµes climÃ¡ticas
- **Hubs**: Aeroportos hub tÃªm maior variabilidade de atrasos

#### ğŸŒ¤ï¸ Impacto ClimÃ¡tico
- **Visibilidade**: CorrelaÃ§Ã£o mais forte (-0.45) com atrasos
- **Temperatura**: Extremos (< 0Â°C ou > 35Â°C) aumentam atrasos
- **Vento**: Velocidades > 25 mph dobram probabilidade de atraso
- **PrecipitaÃ§Ã£o**: Chuva moderada +15 min, forte +35 min mÃ©dia

#### âœˆï¸ Fatores Operacionais
- **Companhias aÃ©reas**: DiferenÃ§a de 2.5x entre melhor e pior performance
- **Tipo de aeronave**: Modelos mais antigos +8 min atraso mÃ©dio
- **Capacidade**: Voos cheios tÃªm +12% probabilidade de atraso
- **DistÃ¢ncia**: Voos > 2000km mostram maior variabilidade

## ğŸ”¬ Experimentos de Modelagem

### ğŸ“‹ Resumo dos Experimentos

#### ğŸ Modelos Baseline (EXP001-003)

**Objetivo**: Estabelecer performance baseline com modelos simples

```python
# EXP001 - Linear Regression
baseline_config = {
    'model': 'LinearRegression',
    'features': 7,  # Features bÃ¡sicas apenas
    'preprocessing': 'StandardScaler',
    'results': {
        'mae': 18.5,
        'rmse': 28.3,
        'r2': 0.62
    }
}

# EXP002 - Random Forest  
rf_basic_config = {
    'model': 'RandomForestRegressor',
    'features': 7,
    'n_estimators': 100,
    'results': {
        'mae': 14.2,
        'rmse': 22.1, 
        'r2': 0.73
    }
}

# EXP003 - XGBoost
xgb_basic_config = {
    'model': 'XGBoostRegressor',
    'features': 7,
    'n_estimators': 100,
    'results': {
        'mae': 13.8,
        'rmse': 21.6,
        'r2': 0.75
    }
}
```

**ConclusÃµes**:
- XGBoost superou RF e Linear por pequena margem
- Todos os modelos mostraram room for improvement significativo
- Feature engineering identificada como prÃ³ximo passo crÃ­tico

#### ğŸš€ Modelos com Feature Engineering (EXP004-006)

**Objetivo**: Melhorar performance atravÃ©s de engenharia de features

```python
# Features engineered criadas
engineered_features = {
    'temporal_cyclical': [
        'hour_sin', 'hour_cos',
        'day_of_week_sin', 'day_of_week_cos', 
        'month_sin', 'month_cos'
    ],
    
    'historical_aggregations': [
        'airport_avg_delay_30d',
        'airline_avg_delay_30d',
        'route_avg_delay_30d'
    ],
    
    'interaction_features': [
        'hour_airport_interaction',
        'weather_distance_interaction',
        'capacity_weather_interaction'
    ],
    
    'categorical_derived': [
        'is_peak_hour',
        'is_long_haul',
        'is_bad_weather',
        'weather_category'
    ],
    
    'density_features': [
        'airport_hour_density',
        'route_daily_frequency'
    ]
}

# Total: 23 features (7 originais + 16 engineered)
```

**Resultados**:
- **EXP004 (RF + Features)**: MAE 12.1 min (â†“15% vs baseline)
- **EXP005 (XGB + Features)**: MAE 11.7 min (â†“18% vs baseline)  
- **EXP006 (LightGBM)**: MAE 11.9 min (â†“16% vs baseline)

#### ğŸ¤– Modelos AvanÃ§ados (EXP007-010)

**EXP007 - Simple Ensemble**
```python
ensemble_simple = {
    'method': 'Weighted Average',
    'models': ['RandomForest', 'XGBoost'],
    'weights': [0.4, 0.6],  # Otimizado via grid search
    'results': {
        'mae': 11.2,
        'rmse': 18.3,
        'r2': 0.83
    }
}
```

**EXP008 - Neural Network**
```python
neural_network = {
    'architecture': '128-64-32-1',
    'activation': 'ReLU',
    'optimizer': 'Adam',
    'learning_rate': 0.001,
    'dropout': 0.3,
    'batch_norm': True,
    'results': {
        'mae': 12.8,  # Surpreendentemente pior
        'rmse': 20.2,
        'r2': 0.77
    }
}
```

**EXP009 - Stacking Ensemble (FINAL)**
```python
stacking_final = {
    'base_models': {
        'rf': RandomForestRegressor(n_estimators=300, max_depth=15),
        'xgb': XGBRegressor(n_estimators=500, learning_rate=0.05),
        'lgb': LGBMRegressor(n_estimators=400, max_depth=10)
    },
    'meta_learner': Ridge(alpha=10.0),
    'cv_folds': 5,
    'results': {
        'mae': 10.8,  # ğŸ† MELHOR RESULTADO
        'rmse': 17.6,
        'r2': 0.85
    }
}
```

### ğŸ“Š AnÃ¡lise de Performance

#### ğŸ¯ Feature Importance

```python
# Top 15 features mais importantes (modelo final)
feature_importance = {
    'hour_sin': 0.142,                    # PadrÃ£o temporal mais forte
    'airport_avg_delay_30d': 0.138,       # HistÃ³rico do aeroporto
    'weather_score_composite': 0.121,     # Score climÃ¡tico composto
    'airline_avg_delay_30d': 0.098,       # HistÃ³rico da companhia
    'distance_km': 0.087,                 # DistÃ¢ncia do voo
    'hour_cos': 0.076,                    # Complementar ao hour_sin
    'day_of_week_encoded': 0.072,         # Dia da semana
    'weather_distance_interaction': 0.065, # InteraÃ§Ã£o clima x distÃ¢ncia
    'airport_congestion': 0.058,          # Congestionamento
    'is_peak_hour': 0.054,               # HorÃ¡rio de pico
    'route_avg_delay_30d': 0.047,         # HistÃ³rico da rota
    'aircraft_age': 0.041,               # Idade da aeronave
    'passenger_load_factor': 0.038,       # Fator de ocupaÃ§Ã£o
    'month_sin': 0.032,                   # Sazonalidade
    'wind_speed': 0.029                   # Velocidade do vento
}
```

#### ğŸš¨ AnÃ¡lise de Erros

```python
error_analysis = {
    'distribution': {
        'mean_error': 0.2,        # Ligeiramente otimista
        'std_error': 17.4,        # Variabilidade moderada
        'skewness': 0.15,         # Levemente assimÃ©trica
        'q95_error': 35.2         # 95% dos erros < 35 min
    },
    
    'by_delay_magnitude': {
        'no_delay': {'mae': 8.2, 'count': '45%'},      # Muito bom para voos pontuais
        '0-15min': {'mae': 9.7, 'count': '28%'},       # Boa precisÃ£o
        '15-30min': {'mae': 12.4, 'count': '15%'},     # RazoÃ¡vel
        '30-60min': {'mae': 18.9, 'count': '8%'},      # Mais difÃ­cil
        '>60min': {'mae': 31.2, 'count': '4%'}         # Casos extremos
    },
    
    'by_conditions': {
        'good_weather': {'mae': 9.1, 'r2': 0.88},
        'moderate_weather': {'mae': 12.3, 'r2': 0.81},
        'bad_weather': {'mae': 16.7, 'r2': 0.74}
    }
}
```

## ğŸ¨ VisualizaÃ§Ãµes e Insights

### ğŸ“Š Dashboards Interativos

#### 1. **Performance Dashboard**
- MÃ©tricas de todos os experimentos
- ComparaÃ§Ã£o temporal de modelos
- Feature importance evolution
- Error analysis detalhado

#### 2. **EDA Dashboard** 
- PadrÃµes temporais interativos
- Mapas geogrÃ¡ficos de atrasos
- CorrelaÃ§Ãµes climÃ¡ticas
- AnÃ¡lise por companhia aÃ©rea

#### 3. **Model Monitoring Dashboard**
- Performance em tempo real
- Data drift detection
- Model degradation alerts
- Prediction confidence distribution

### ğŸ¯ Principais VisualizaÃ§Ãµes

```python
# Exemplo de visualizaÃ§Ã£o de performance temporal
def create_temporal_performance_viz():
    """Cria visualizaÃ§Ã£o da evoluÃ§Ã£o da performance dos modelos"""
    
    experiments = [
        {'date': '2024-01-10', 'model': 'Linear', 'mae': 18.5},
        {'date': '2024-01-11', 'model': 'RF Basic', 'mae': 14.2},
        {'date': '2024-01-12', 'model': 'XGB Basic', 'mae': 13.8},
        {'date': '2024-01-13', 'model': 'RF + Features', 'mae': 12.1},
        {'date': '2024-01-14', 'model': 'XGB + Features', 'mae': 11.7},
        {'date': '2024-01-15', 'model': 'LightGBM', 'mae': 11.9},
        {'date': '2024-01-16', 'model': 'Simple Ensemble', 'mae': 11.2},
        {'date': '2024-01-17', 'model': 'Neural Net', 'mae': 12.8},
        {'date': '2024-01-18', 'model': 'Stacking', 'mae': 10.8},
        {'date': '2024-01-19', 'model': 'AutoML', 'mae': 11.1}
    ]
    
    df = pd.DataFrame(experiments)
    df['date'] = pd.to_datetime(df['date'])
    
    fig = px.line(
        df, x='date', y='mae', 
        title='EvoluÃ§Ã£o da Performance dos Modelos',
        labels={'mae': 'MAE (minutos)', 'date': 'Data do Experimento'},
        markers=True
    )
    
    fig.add_hline(
        y=15, line_dash="dash", line_color="red",
        annotation_text="Meta: MAE < 15 min"
    )
    
    return fig
```

## ğŸ”„ Metodologia de ExperimentaÃ§Ã£o

### ğŸ“‹ Protocolo PadrÃ£o

#### 1. **Setup do Experimento**
```python
experiment_protocol = {
    'data_split': {
        'method': 'temporal_split',
        'train_period': '2023-01-01 to 2023-10-31',
        'validation_period': '2023-11-01 to 2023-11-30', 
        'test_period': '2023-12-01 to 2023-12-31'
    },
    
    'validation_strategy': {
        'method': 'TimeSeriesSplit',
        'n_splits': 5,
        'gap': 7  # 7 days gap between train/validation
    },
    
    'metrics': {
        'primary': 'MAE',
        'secondary': ['RMSE', 'RÂ²', 'MAPE'],
        'business': ['accuracy_15min', 'precision_30min']
    },
    
    'tracking': {
        'tool': 'MLflow',
        'log_artifacts': True,
        'log_model': True,
        'log_hyperparameters': True
    }
}
```

#### 2. **CritÃ©rios de AvaliaÃ§Ã£o**
```python
evaluation_criteria = {
    'performance_thresholds': {
        'mae_target': 12.0,      # < 12 min MAE
        'r2_minimum': 0.80,      # > 80% variÃ¢ncia explicada  
        'accuracy_15min': 0.85   # 85% acerto para atrasos >15min
    },
    
    'robustness_tests': {
        'cross_validation': 'TimeSeriesSplit(n=5)',
        'holdout_validation': 'Future 1 month',
        'bootstrap_confidence': 'n=1000 samples'
    },
    
    'business_requirements': {
        'latency': '<100ms per prediction',
        'throughput': '>1000 predictions/sec',
        'memory': '<2GB model size'
    }
}
```

### ğŸ§ª Lessons Learned

#### âœ… O que Funcionou Bem

1. **Feature Engineering Temporal**: Features cÃ­clicas capturaram padrÃµes sazonais
2. **AgregaÃ§Ãµes HistÃ³ricas**: MÃ©dias mÃ³veis melhoraram significativamente a performance  
3. **Stacking Ensemble**: Combinou pontos fortes de diferentes algoritmos
4. **ValidaÃ§Ã£o Temporal**: Evitou data leakage e overfitting

#### âŒ O que NÃ£o Funcionou

1. **Deep Learning**: Neural networks nÃ£o superaram tree-based models
2. **Muitas Features**: AlÃ©m de 35 features houve overfitting
3. **Dados ClimÃ¡ticos Externos**: APIs instÃ¡veis afetaram reprodutibilidade
4. **OtimizaÃ§Ã£o Excessiva**: Hyperparameter tuning com pouco ganho vs custo

#### ğŸ¯ PrÃ³ximas IteraÃ§Ãµes

1. **Modelos EspecÃ­ficos**: Por aeroporto, companhia aÃ©rea ou rota
2. **Online Learning**: AtualizaÃ§Ã£o contÃ­nua com novos dados
3. **Multi-task Learning**: Predizer mÃºltiplas mÃ©tricas simultaneamente
4. **Ensemble DinÃ¢mico**: Weights adaptativos baseados em contexto

## ğŸ“ Estrutura dos Notebooks

### ğŸ“‚ OrganizaÃ§Ã£o Recomendada

```
notebook/
â”œâ”€â”€ 01_data_exploration/
â”‚   â”œâ”€â”€ eda_temporal_patterns.ipynb      # PadrÃµes temporais
â”‚   â”œâ”€â”€ eda_geographic_analysis.ipynb    # AnÃ¡lise geogrÃ¡fica  
â”‚   â”œâ”€â”€ eda_weather_impact.ipynb        # Impacto climÃ¡tico
â”‚   â””â”€â”€ eda_operational_factors.ipynb   # Fatores operacionais
â”‚
â”œâ”€â”€ 02_feature_engineering/
â”‚   â”œâ”€â”€ feature_creation.ipynb          # CriaÃ§Ã£o de features
â”‚   â”œâ”€â”€ feature_selection.ipynb         # SeleÃ§Ã£o de features
â”‚   â””â”€â”€ feature_validation.ipynb        # ValidaÃ§Ã£o de features
â”‚
â”œâ”€â”€ 03_modeling/
â”‚   â”œâ”€â”€ baseline_models.ipynb           # Modelos baseline
â”‚   â”œâ”€â”€ advanced_models.ipynb           # Modelos avanÃ§ados
â”‚   â”œâ”€â”€ ensemble_methods.ipynb          # MÃ©todos de ensemble
â”‚   â””â”€â”€ model_comparison.ipynb          # ComparaÃ§Ã£o final
â”‚
â”œâ”€â”€ 04_evaluation/
â”‚   â”œâ”€â”€ performance_analysis.ipynb      # AnÃ¡lise de performance
â”‚   â”œâ”€â”€ error_analysis.ipynb           # AnÃ¡lise de erros
â”‚   â””â”€â”€ business_impact.ipynb          # Impacto no negÃ³cio
â”‚
â””â”€â”€ 05_deployment/
    â”œâ”€â”€ model_optimization.ipynb        # OtimizaÃ§Ã£o para produÃ§Ã£o
    â”œâ”€â”€ monitoring_setup.ipynb          # Setup de monitoramento
    â””â”€â”€ inference_testing.ipynb         # Testes de inferÃªncia
```

### ğŸ”§ Template de Notebook

```python
# =============================================================================
# NOTEBOOK TEMPLATE - Flight Delay Prediction
# =============================================================================

# %% [markdown]
"""
# [TÃTULO DO NOTEBOOK]

**Objetivo:** [Descrever objetivo especÃ­fico]  
**Dataset:** [Fonte e perÃ­odo dos dados]  
**Autor:** [Nome do autor]  
**Data:** [Data de criaÃ§Ã£o]  
**VersÃ£o:** [VersÃ£o do notebook]

## Ãndice
1. [Setup e ConfiguraÃ§Ã£o](#setup)
2. [Carregamento de Dados](#data-loading)  
3. [AnÃ¡lise Principal](#main-analysis)
4. [Resultados e ConclusÃµes](#results)
5. [PrÃ³ximos Passos](#next-steps)
"""

# %% [markdown]
# ## 1. Setup e ConfiguraÃ§Ã£o {#setup}

# %%
# Imports bÃ¡sicos
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings

# ConfiguraÃ§Ãµes
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

# ConfiguraÃ§Ãµes globais
RANDOM_STATE = 42
DATA_PATH = Path("../data/")
FIGURES_PATH = Path("../figures/")
RESULTS_PATH = Path("../results/")

print("âœ… Setup concluÃ­do")

# %% [markdown]  
# ## 2. Carregamento de Dados {#data-loading}

# %%
def load_and_validate_data(filepath: Path) -> pd.DataFrame:
    """
    Carrega e valida dados de entrada.
    
    Args:
        filepath: Caminho para o arquivo de dados
        
    Returns:
        DataFrame validado
    """
    # ImplementaÃ§Ã£o especÃ­fica
    pass

# Carregar dados
df = load_and_validate_data(DATA_PATH / "flight_data.csv")
print(f"ğŸ“Š Dados carregados: {df.shape}")

# %% [markdown]
# ## 3. AnÃ¡lise Principal {#main-analysis}

# [CÃ©lulas especÃ­ficas da anÃ¡lise]

# %% [markdown]
# ## 4. Resultados e ConclusÃµes {#results}

# [Resumo dos resultados]

# %% [markdown]
# ## 5. PrÃ³ximos Passos {#next-steps}

# [Lista de prÃ³ximas aÃ§Ãµes]
```

## ğŸ”— Links Ãšteis

### ğŸ“š DocumentaÃ§Ã£o Relacionada

- **[ğŸ“Š EDA Documentation](eda.md)** - AnÃ¡lise exploratÃ³ria detalhada
- **[ğŸ¤– Modeling Guide](modeling.md)** - Guia completo de modelagem
- **[ğŸ”„ Data Analysis](../ml/data-analysis.md)** - Metodologias de anÃ¡lise
- **[ğŸ¯ Model Training](../ml/model-training.md)** - Treinamento de modelos

### ğŸ› ï¸ Ferramentas e Recursos

- **[Jupyter Lab](https://jupyter.org/)** - Ambiente de desenvolvimento
- **[MLflow](https://mlflow.org/)** - Tracking de experimentos  
- **[Pandas Profiling](https://pandas-profiling.github.io/)** - RelatÃ³rios automÃ¡ticos
- **[Plotly](https://plotly.com/python/)** - VisualizaÃ§Ãµes interativas

---

## ğŸ“ Contato e Suporte

Para dÃºvidas sobre notebooks ou experimentos:
- ğŸ“§ **Email**: data-science@project.com
- ğŸ’¬ **Slack**: #data-science-help
- ğŸ“š **Wiki**: DocumentaÃ§Ã£o interna do projeto