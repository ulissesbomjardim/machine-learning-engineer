# üß™ Experimentos e Notebooks

Documenta√ß√£o completa dos experimentos realizados, notebooks de an√°lise e metodologias utilizadas no desenvolvimento do sistema de predi√ß√£o de atrasos de voos.

## üìì Notebooks Dispon√≠veis

### üéØ Notebooks Principais

| **Notebook** | **Descri√ß√£o** | **Status** | **√öltima Atualiza√ß√£o** |
|-------------|---------------|------------|------------------------|
| `analise_exploratoria_de_dados.ipynb` | EDA completa dos dados de voos | ‚úÖ Completo | 2024-01-20 |
| `Model.ipynb` | Desenvolvimento e compara√ß√£o de modelos | ‚úÖ Completo | 2024-01-18 |
| `Transform.ipynb` | Pipeline de transforma√ß√£o de dados | ‚úÖ Completo | 2024-01-15 |
| `Profiling.ipynb` | Profiling detalhado dos dados | ‚úÖ Completo | 2024-01-12 |
| `perguntas.ipynb` | Investiga√ß√£o de quest√µes espec√≠ficas | ‚úÖ Completo | 2024-01-10 |

### üß™ Experimentos de Modelagem

#### üìä Cronologia dos Experimentos

```mermaid
timeline
    title Cronologia dos Experimentos de ML
    
    Jan 10 : EXP001 - Baseline Linear
           : MAE 18.5 min
           
    Jan 11 : EXP002 - Random Forest B√°sico
           : MAE 14.2 min
           
    Jan 12 : EXP003 - XGBoost B√°sico
           : MAE 13.8 min
           
    Jan 13 : EXP004 - Random Forest + Feature Engineering
           : MAE 12.1 min
           
    Jan 14 : EXP005 - XGBoost Otimizado
           : MAE 11.7 min
           
    Jan 15 : EXP006 - LightGBM
           : MAE 11.9 min
           
    Jan 16 : EXP007 - Ensemble RF+XGB
           : MAE 11.2 min
           
    Jan 17 : EXP008 - Neural Network
           : MAE 12.8 min
           
    Jan 18 : EXP009 - Stacking Ensemble
           : MAE 10.8 min (FINAL)
           
    Jan 19 : EXP010 - AutoML H2O
           : MAE 11.1 min
```

## üìä An√°lise Explorat√≥ria de Dados

### üéØ Objetivo da EDA

A an√°lise explorat√≥ria foi conduzida para:

1. **Entender os dados**: Distribui√ß√µes, padr√µes e anomalias
2. **Identificar features relevantes**: Vari√°veis que impactam atrasos
3. **Descobrir insights**: Padr√µes temporais, geogr√°ficos e operacionais
4. **Guiar feature engineering**: Cria√ß√£o de novas vari√°veis
5. **Definir estrat√©gias**: Preprocessamento e modelagem

### üìà Principais Descobertas

```python
# Principais insights da EDA
eda_insights = {
    'temporal_patterns': {
        'peak_delay_hours': [17, 18, 19, 20],  # 17h-20h
        'worst_day': 'Friday',  # Sexta-feira
        'seasonal_impact': 'Winter months show 15% more delays'
    },
    
    'geographic_patterns': {
        'worst_airports': ['ORD', 'ATL', 'LAX'],  # Por volume e clima
        'best_airports': ['SEA', 'PDX', 'SLC'],   # Menor congestionamento
        'route_impact': 'Long-haul flights 23% more delays'
    },
    
    'weather_impact': {
        'strongest_correlation': 'visibility',  # -0.45 com atrasos
        'temperature_effect': 'Extremes (< 0¬∞C or > 35¬∞C) increase delays',
        'wind_threshold': '25+ mph doubles delay probability'
    },
    
    'operational_factors': {
        'airline_variance': '2.5x difference between best and worst',
        'aircraft_impact': 'Older aircraft models +8min average delay',
        'capacity_effect': 'Full flights +12% delay probability'
    }
}
```

### üåü Insights Principais

#### üïê Padr√µes Temporais
- **Hor√°rios de pico**: 17h-20h apresentam 40% mais atrasos
- **Dias da semana**: Sextas-feiras t√™m os maiores atrasos (m√©dia +8 min)
- **Sazonalidade**: Meses de inverno mostram 15% mais atrasos
- **Feriados**: V√©speras de feriados aumentam atrasos em 25%

#### üåç Padr√µes Geogr√°ficos
- **Aeroportos problem√°ticos**: ORD, ATL, LAX devido ao volume e clima
- **Rotas cr√≠ticas**: Voos transcontinentais t√™m 23% mais atrasos
- **Regi√µes**: Costa leste mais afetada por condi√ß√µes clim√°ticas
- **Hubs**: Aeroportos hub t√™m maior variabilidade de atrasos

#### üå§Ô∏è Impacto Clim√°tico
- **Visibilidade**: Correla√ß√£o mais forte (-0.45) com atrasos
- **Temperatura**: Extremos (< 0¬∞C ou > 35¬∞C) aumentam atrasos
- **Vento**: Velocidades > 25 mph dobram probabilidade de atraso
- **Precipita√ß√£o**: Chuva moderada +15 min, forte +35 min m√©dia

#### ‚úàÔ∏è Fatores Operacionais
- **Companhias a√©reas**: Diferen√ßa de 2.5x entre melhor e pior performance
- **Tipo de aeronave**: Modelos mais antigos +8 min atraso m√©dio
- **Capacidade**: Voos cheios t√™m +12% probabilidade de atraso
- **Dist√¢ncia**: Voos > 2000km mostram maior variabilidade

## üî¨ Experimentos de Modelagem

### üìã Resumo dos Experimentos

#### üèÅ Modelos Baseline (EXP001-003)

**Objetivo**: Estabelecer performance baseline com modelos simples

```python
# EXP001 - Linear Regression
baseline_config = {
    'model': 'LinearRegression',
    'features': 7,  # Features b√°sicas apenas
    'preprocessing': 'StandardScaler',
    'results': {
        'mae': 18.5,
        'rmse': 28.3,
        'r2': 0.62
    }
}

# EXP002 - Random Forest  
rf_basic_config = {
    'model': 'RandomForestRegressor',
    'features': 7,
    'n_estimators': 100,
    'results': {
        'mae': 14.2,
        'rmse': 22.1, 
        'r2': 0.73
    }
}

# EXP003 - XGBoost
xgb_basic_config = {
    'model': 'XGBoostRegressor',
    'features': 7,
    'n_estimators': 100,
    'results': {
        'mae': 13.8,
        'rmse': 21.6,
        'r2': 0.75
    }
}
```

**Conclus√µes**:
- XGBoost superou RF e Linear por pequena margem
- Todos os modelos mostraram room for improvement significativo
- Feature engineering identificada como pr√≥ximo passo cr√≠tico

#### üöÄ Modelos com Feature Engineering (EXP004-006)

**Objetivo**: Melhorar performance atrav√©s de engenharia de features

```python
# Features engineered criadas
engineered_features = {
    'temporal_cyclical': [
        'hour_sin', 'hour_cos',
        'day_of_week_sin', 'day_of_week_cos', 
        'month_sin', 'month_cos'
    ],
    
    'historical_aggregations': [
        'airport_avg_delay_30d',
        'airline_avg_delay_30d',
        'route_avg_delay_30d'
    ],
    
    'interaction_features': [
        'hour_airport_interaction',
        'weather_distance_interaction',
        'capacity_weather_interaction'
    ],
    
    'categorical_derived': [
        'is_peak_hour',
        'is_long_haul',
        'is_bad_weather',
        'weather_category'
    ],
    
    'density_features': [
        'airport_hour_density',
        'route_daily_frequency'
    ]
}

# Total: 23 features (7 originais + 16 engineered)
```

**Resultados**:
- **EXP004 (RF + Features)**: MAE 12.1 min (‚Üì15% vs baseline)
- **EXP005 (XGB + Features)**: MAE 11.7 min (‚Üì18% vs baseline)  
- **EXP006 (LightGBM)**: MAE 11.9 min (‚Üì16% vs baseline)

#### ü§ñ Modelos Avan√ßados (EXP007-010)

**EXP007 - Simple Ensemble**
```python
ensemble_simple = {
    'method': 'Weighted Average',
    'models': ['RandomForest', 'XGBoost'],
    'weights': [0.4, 0.6],  # Otimizado via grid search
    'results': {
        'mae': 11.2,
        'rmse': 18.3,
        'r2': 0.83
    }
}
```

**EXP008 - Neural Network**
```python
neural_network = {
    'architecture': '128-64-32-1',
    'activation': 'ReLU',
    'optimizer': 'Adam',
    'learning_rate': 0.001,
    'dropout': 0.3,
    'batch_norm': True,
    'results': {
        'mae': 12.8,  # Surpreendentemente pior
        'rmse': 20.2,
        'r2': 0.77
    }
}
```

**EXP009 - Stacking Ensemble (FINAL)**
```python
stacking_final = {
    'base_models': {
        'rf': RandomForestRegressor(n_estimators=300, max_depth=15),
        'xgb': XGBRegressor(n_estimators=500, learning_rate=0.05),
        'lgb': LGBMRegressor(n_estimators=400, max_depth=10)
    },
    'meta_learner': Ridge(alpha=10.0),
    'cv_folds': 5,
    'results': {
        'mae': 10.8,  # üèÜ MELHOR RESULTADO
        'rmse': 17.6,
        'r2': 0.85
    }
}
```

### üìä An√°lise de Performance

#### üéØ Feature Importance

```python
# Top 15 features mais importantes (modelo final)
feature_importance = {
    'hour_sin': 0.142,                    # Padr√£o temporal mais forte
    'airport_avg_delay_30d': 0.138,       # Hist√≥rico do aeroporto
    'weather_score_composite': 0.121,     # Score clim√°tico composto
    'airline_avg_delay_30d': 0.098,       # Hist√≥rico da companhia
    'distance_km': 0.087,                 # Dist√¢ncia do voo
    'hour_cos': 0.076,                    # Complementar ao hour_sin
    'day_of_week_encoded': 0.072,         # Dia da semana
    'weather_distance_interaction': 0.065, # Intera√ß√£o clima x dist√¢ncia
    'airport_congestion': 0.058,          # Congestionamento
    'is_peak_hour': 0.054,               # Hor√°rio de pico
    'route_avg_delay_30d': 0.047,         # Hist√≥rico da rota
    'aircraft_age': 0.041,               # Idade da aeronave
    'passenger_load_factor': 0.038,       # Fator de ocupa√ß√£o
    'month_sin': 0.032,                   # Sazonalidade
    'wind_speed': 0.029                   # Velocidade do vento
}
```

#### üö® An√°lise de Erros

```python
error_analysis = {
    'distribution': {
        'mean_error': 0.2,        # Ligeiramente otimista
        'std_error': 17.4,        # Variabilidade moderada
        'skewness': 0.15,         # Levemente assim√©trica
        'q95_error': 35.2         # 95% dos erros < 35 min
    },
    
    'by_delay_magnitude': {
        'no_delay': {'mae': 8.2, 'count': '45%'},      # Muito bom para voos pontuais
        '0-15min': {'mae': 9.7, 'count': '28%'},       # Boa precis√£o
        '15-30min': {'mae': 12.4, 'count': '15%'},     # Razo√°vel
        '30-60min': {'mae': 18.9, 'count': '8%'},      # Mais dif√≠cil
        '>60min': {'mae': 31.2, 'count': '4%'}         # Casos extremos
    },
    
    'by_conditions': {
        'good_weather': {'mae': 9.1, 'r2': 0.88},
        'moderate_weather': {'mae': 12.3, 'r2': 0.81},
        'bad_weather': {'mae': 16.7, 'r2': 0.74}
    }
}
```

## üé® Visualiza√ß√µes e Insights

### üìä Dashboards Interativos

#### 1. **Performance Dashboard**
- M√©tricas de todos os experimentos
- Compara√ß√£o temporal de modelos
- Feature importance evolution
- Error analysis detalhado

#### 2. **EDA Dashboard** 
- Padr√µes temporais interativos
- Mapas geogr√°ficos de atrasos
- Correla√ß√µes clim√°ticas
- An√°lise por companhia a√©rea

#### 3. **Model Monitoring Dashboard**
- Performance em tempo real
- Data drift detection
- Model degradation alerts
- Prediction confidence distribution

### üéØ Principais Visualiza√ß√µes

```python
# Exemplo de visualiza√ß√£o de performance temporal
def create_temporal_performance_viz():
    """Cria visualiza√ß√£o da evolu√ß√£o da performance dos modelos"""
    
    experiments = [
        {'date': '2024-01-10', 'model': 'Linear', 'mae': 18.5},
        {'date': '2024-01-11', 'model': 'RF Basic', 'mae': 14.2},
        {'date': '2024-01-12', 'model': 'XGB Basic', 'mae': 13.8},
        {'date': '2024-01-13', 'model': 'RF + Features', 'mae': 12.1},
        {'date': '2024-01-14', 'model': 'XGB + Features', 'mae': 11.7},
        {'date': '2024-01-15', 'model': 'LightGBM', 'mae': 11.9},
        {'date': '2024-01-16', 'model': 'Simple Ensemble', 'mae': 11.2},
        {'date': '2024-01-17', 'model': 'Neural Net', 'mae': 12.8},
        {'date': '2024-01-18', 'model': 'Stacking', 'mae': 10.8},
        {'date': '2024-01-19', 'model': 'AutoML', 'mae': 11.1}
    ]
    
    df = pd.DataFrame(experiments)
    df['date'] = pd.to_datetime(df['date'])
    
    fig = px.line(
        df, x='date', y='mae', 
        title='Evolu√ß√£o da Performance dos Modelos',
        labels={'mae': 'MAE (minutos)', 'date': 'Data do Experimento'},
        markers=True
    )
    
    fig.add_hline(
        y=15, line_dash="dash", line_color="red",
        annotation_text="Meta: MAE < 15 min"
    )
    
    return fig
```

## üîÑ Metodologia de Experimenta√ß√£o

### üìã Protocolo Padr√£o

#### 1. **Setup do Experimento**
```python
experiment_protocol = {
    'data_split': {
        'method': 'temporal_split',
        'train_period': '2023-01-01 to 2023-10-31',
        'validation_period': '2023-11-01 to 2023-11-30', 
        'test_period': '2023-12-01 to 2023-12-31'
    },
    
    'validation_strategy': {
        'method': 'TimeSeriesSplit',
        'n_splits': 5,
        'gap': 7  # 7 days gap between train/validation
    },
    
    'metrics': {
        'primary': 'MAE',
        'secondary': ['RMSE', 'R¬≤', 'MAPE'],
        'business': ['accuracy_15min', 'precision_30min']
    },
    
    'tracking': {
        'tool': 'MLflow',
        'log_artifacts': True,
        'log_model': True,
        'log_hyperparameters': True
    }
}
```

#### 2. **Crit√©rios de Avalia√ß√£o**
```python
evaluation_criteria = {
    'performance_thresholds': {
        'mae_target': 12.0,      # < 12 min MAE
        'r2_minimum': 0.80,      # > 80% vari√¢ncia explicada  
        'accuracy_15min': 0.85   # 85% acerto para atrasos >15min
    },
    
    'robustness_tests': {
        'cross_validation': 'TimeSeriesSplit(n=5)',
        'holdout_validation': 'Future 1 month',
        'bootstrap_confidence': 'n=1000 samples'
    },
    
    'business_requirements': {
        'latency': '<100ms per prediction',
        'throughput': '>1000 predictions/sec',
        'memory': '<2GB model size'
    }
}
```

### üß™ Lessons Learned

#### ‚úÖ O que Funcionou Bem

1. **Feature Engineering Temporal**: Features c√≠clicas capturaram padr√µes sazonais
2. **Agrega√ß√µes Hist√≥ricas**: M√©dias m√≥veis melhoraram significativamente a performance  
3. **Stacking Ensemble**: Combinou pontos fortes de diferentes algoritmos
4. **Valida√ß√£o Temporal**: Evitou data leakage e overfitting

#### ‚ùå O que N√£o Funcionou

1. **Deep Learning**: Neural networks n√£o superaram tree-based models
2. **Muitas Features**: Al√©m de 35 features houve overfitting
3. **Dados Clim√°ticos Externos**: APIs inst√°veis afetaram reprodutibilidade
4. **Otimiza√ß√£o Excessiva**: Hyperparameter tuning com pouco ganho vs custo

#### üéØ Pr√≥ximas Itera√ß√µes

1. **Modelos Espec√≠ficos**: Por aeroporto, companhia a√©rea ou rota
2. **Online Learning**: Atualiza√ß√£o cont√≠nua com novos dados
3. **Multi-task Learning**: Predizer m√∫ltiplas m√©tricas simultaneamente
4. **Ensemble Din√¢mico**: Weights adaptativos baseados em contexto

## üìÅ Estrutura dos Notebooks

### üìÇ Organiza√ß√£o Recomendada

```
notebook/
‚îú‚îÄ‚îÄ 01_data_exploration/
‚îÇ   ‚îú‚îÄ‚îÄ eda_temporal_patterns.ipynb      # Padr√µes temporais
‚îÇ   ‚îú‚îÄ‚îÄ eda_geographic_analysis.ipynb    # An√°lise geogr√°fica  
‚îÇ   ‚îú‚îÄ‚îÄ eda_weather_impact.ipynb        # Impacto clim√°tico
‚îÇ   ‚îî‚îÄ‚îÄ eda_operational_factors.ipynb   # Fatores operacionais
‚îÇ
‚îú‚îÄ‚îÄ 02_feature_engineering/
‚îÇ   ‚îú‚îÄ‚îÄ feature_creation.ipynb          # Cria√ß√£o de features
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection.ipynb         # Sele√ß√£o de features
‚îÇ   ‚îî‚îÄ‚îÄ feature_validation.ipynb        # Valida√ß√£o de features
‚îÇ
‚îú‚îÄ‚îÄ 03_modeling/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_models.ipynb           # Modelos baseline
‚îÇ   ‚îú‚îÄ‚îÄ advanced_models.ipynb           # Modelos avan√ßados
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_methods.ipynb          # M√©todos de ensemble
‚îÇ   ‚îî‚îÄ‚îÄ model_comparison.ipynb          # Compara√ß√£o final
‚îÇ
‚îú‚îÄ‚îÄ 04_evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ performance_analysis.ipynb      # An√°lise de performance
‚îÇ   ‚îú‚îÄ‚îÄ error_analysis.ipynb           # An√°lise de erros
‚îÇ   ‚îî‚îÄ‚îÄ business_impact.ipynb          # Impacto no neg√≥cio
‚îÇ
‚îî‚îÄ‚îÄ 05_deployment/
    ‚îú‚îÄ‚îÄ model_optimization.ipynb        # Otimiza√ß√£o para produ√ß√£o
    ‚îú‚îÄ‚îÄ monitoring_setup.ipynb          # Setup de monitoramento
    ‚îî‚îÄ‚îÄ inference_testing.ipynb         # Testes de infer√™ncia
```

### üîß Template de Notebook

```python
# =============================================================================
# NOTEBOOK TEMPLATE - Flight Delay Prediction
# =============================================================================

# %% [markdown]
"""
# [T√çTULO DO NOTEBOOK]

**Objetivo:** [Descrever objetivo espec√≠fico]  
**Dataset:** [Fonte e per√≠odo dos dados]  
**Autor:** [Nome do autor]  
**Data:** [Data de cria√ß√£o]  
**Vers√£o:** [Vers√£o do notebook]

## √çndice
1. [Setup e Configura√ß√£o](#setup)
2. [Carregamento de Dados](#data-loading)  
3. [An√°lise Principal](#main-analysis)
4. [Resultados e Conclus√µes](#results)
5. [Pr√≥ximos Passos](#next-steps)
"""

# %% [markdown]
# ## 1. Setup e Configura√ß√£o {#setup}

# %%
# Imports b√°sicos
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings

# Configura√ß√µes
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

%matplotlib inline
%config InlineBackend.figure_format = 'retina'

# Configura√ß√µes globais
RANDOM_STATE = 42
DATA_PATH = Path("../data/")
FIGURES_PATH = Path("../figures/")
RESULTS_PATH = Path("../results/")

print("‚úÖ Setup conclu√≠do")

# %% [markdown]  
# ## 2. Carregamento de Dados {#data-loading}

# %%
def load_and_validate_data(filepath: Path) -> pd.DataFrame:
    """
    Carrega e valida dados de entrada.
    
    Args:
        filepath: Caminho para o arquivo de dados
        
    Returns:
        DataFrame validado
    """
    # Implementa√ß√£o espec√≠fica
    pass

# Carregar dados
df = load_and_validate_data(DATA_PATH / "flight_data.csv")
print(f"üìä Dados carregados: {df.shape}")

# %% [markdown]
# ## 3. An√°lise Principal {#main-analysis}

# [C√©lulas espec√≠ficas da an√°lise]

# %% [markdown]
# ## 4. Resultados e Conclus√µes {#results}

# [Resumo dos resultados]

# %% [markdown]
# ## 5. Pr√≥ximos Passos {#next-steps}

# [Lista de pr√≥ximas a√ß√µes]
```

## üîó Links √öteis

### üìö Documenta√ß√£o Relacionada

- **[üìä EDA Documentation](eda.md)** - An√°lise explorat√≥ria detalhada
- **[ü§ñ Modeling Guide](modeling.md)** - Guia completo de modelagem
- **[üîÑ Data Analysis](../ml/data-analysis.md)** - Metodologias de an√°lise
- **[üéØ Model Training](../ml/model-training.md)** - Treinamento de modelos

### üõ†Ô∏è Ferramentas e Recursos

- **[Jupyter Lab](https://jupyter.org/)** - Ambiente de desenvolvimento
- **[MLflow](https://mlflow.org/)** - Tracking de experimentos  
- **[Pandas Profiling](https://pandas-profiling.github.io/)** - Relat√≥rios autom√°ticos
- **[Plotly](https://plotly.com/python/)** - Visualiza√ß√µes interativas

---

## üìû Contato e Suporte

Para d√∫vidas sobre notebooks ou experimentos:
- üìß **Email**: data-science@project.com
- üí¨ **Slack**: #data-science-help
- üìö **Wiki**: Documenta√ß√£o interna do projeto